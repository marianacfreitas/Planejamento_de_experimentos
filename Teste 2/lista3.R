library(dplyr)

############ QUEST√ÉO 1

peso <- c(1.3, 1.26, 1.05, 1.52, 1.19, 1.21, 1.00, 1.56, 1.08, 1.19,
          1.05, 1.55)

antib <- rep(c("A0", "A0", "A1", "A1"), 3)
vitam <- rep(c("B0", "B1"), 6)

data <- data.frame(aumento = peso, antibiotico = antib, vitamina = vitam)

## Construindo a tabela Anova
modelo <-  with(data, aov(aumento ~ antibiotico*vitamina))
tabela_anova <- anova(modelo)
tabela_anova
#se o valor p for menos que o \alpha, os n√≠veis do o fator ou intera√ß√£o tem um efeito estatisticamente significativo

## Valor da tabela F para um n√≠vel de signific√¢ncia de \alpha = 0.05

#f cr√≠tico para o antibi√≥tico
gl_numerador <- tabela_anova$Df[1]  # Graus de liberdade do numerador (fator)
gl_denominador <- tabela_anova$Df[4]  # Graus de liberdade do denominador (res√≠duos)
qf(0.05, gl_numerador, gl_denominador, lower.tail = FALSE)
# como o F cr√≠tico para o antibi√≥tico da tabela anova √© maior que o f cr√≠tico, rejeitamos
#a hip√≥tese de m√©dias iguais entre diferentes n√≠veis (H_0)

## Teste dos pressupostos

#Normalidadade dos erros

#h_0: res√≠duos tem distribui√ß√£o normal
#h_1: res√≠duos n√£o t√™m distribui√ß√£o normal
#W: quanto mais pr√≥ximo de 1, mais os res√≠duos se aproximam de uma distribui√ß√£o normal
#se valor-p > \alpha, n√£o rejeitmaos h_0
(norm=shapiro.test(modelo$residuals))


#QQ plot
library(hnp)
hnp::hnp(modelo, las=1, xlab="Quantis te√≥ricos", pch=16, main="qq-plot dos res√≠duos")

#Heterogeneidade das variancias - Fator 1
#h_0: vari√¢ncias homog√™neas
#h_1: vari√¢ncia diferente em pelo menos um grupo
#se p-valor < \alpha, rejeitamos a hip√≥tese nula
with(data, bartlett.test(modelo$residuals~antibiotico))

#Heterogeneidade das variancias - Fator 2
with(data, bartlett.test(modelo$residuals~vitamina))

#Heterogeneidade das vari√¢ncias - juntandos os fatores
#considerar cada combina√ß√£o dos dois n√≠veis como um tratamento diferente:
data <- data |>
  mutate(
    tratamento = case_when(
      antibiotico == "A1" & vitamina == "B1" ~ "t11",
      antibiotico == "A1" & vitamina == "B0" ~ "t10",
      antibiotico == "A0" & vitamina == "B0" ~ "t00",
      antibiotico == "A0" & vitamina == "B1" ~ "t01"
    )
  )
with(data, bartlett.test(modelo$residuals~tratamento))

library(ggplot2)
ggplot(data, aes(x=tratamento, y=aumento, fill=tratamento)) +
  geom_boxplot()

#Independencia dos erros
#h_0: n√£o h√° autocorrela√ß√£o significativa entre os res√≠duos
#p-valor > \alpha indica que n√£o rejeitamos h_0
(ind=lmtest::dwtest(modelo))

#Graficos dos residuos em sequencia
plot(modelo$res, las=1, pch=19, col='red', ylab='Res√≠duos brutos')
abline(h=0)

## Teste de compara√ß√µes m√∫ltiplas

#Como todos os dois fatores e sua intera√ß√£o foram significativos, faremos o teste tr√™s vezes
library(ExpDes.pt)
with(data,fat2.dic(antibiotico,vitamina,aumento, mcomp="tukey"))
# Um valor-p baixo (geralmente < 0,05) indica que a diferen√ßa entre os n√≠veis √© estatisticamente significativa


############### QUEST√ÉO 2
library(car)  
library(rsm)

# Criar o conjunto de dados
dados <- data.frame(
  x1 = c(-1, -1, 1, 1, 0, 0, 0, 0, 0),
  x2 = c(-1, 1, -1, 1, 0, 0, 0, 0, 0),
  X1 = c(80,80, 90, 90, rep(85, 5)),
  X2 = c(rep(c(170, 180), 2), rep(175, 5)),
  Y = c(76.5, 77.0, 78.0, 79.5, 79.9, 80.3, 80.0, 79.7, 79.8)
)

dados <- as.coded.data(dados,
                      x1 ~ (X1-85)/5,
                      x2 ~ (X2 - 175)/5)

# Regress√£o considerando os efeitos principais e as intera√ß√µes entre os dois fatores
ciro <- rsm(Y ~ FO(x1, x2) + TWI(x1, x2), data = dados)
summary(ciro)

#Agora os c√°lculos sem intera√ß√£o
model <- rsm(Y ~ FO(x1, x2), data = dados)
summary(model)

#Comparando os dois modelos
anova(model, ciro)
#RSS(Residual Sum of Squares): Mede o erro do modelo - o modelo com intera√ß√£o apresenta um erro um pouco menor, mas quase igual
#Sum of Sq (Soma dos Quadrados Explicada pelo Novo Termo): Diferen√ßa de erro entre os modelos - apenas 0.25, ou seja, a intera√ß√£o n√£o explicou muita coisa
#F: Mede a melhoria do ajuste ao adicionar a intera√ß√£o - 0.115, um valor muito pequeno
#Valor-p: Mede se a melhoria no ajuste √© estatisticamente significativa - 0.7483, um valor muito maior que 0.05 ‚Üí N√£o h√° evid√™ncia estat√≠stica para manter a intera√ß√£o
#Assim, modelo sem intera√ß√£o escolhido

#Modelo linear inicial
cat(sprintf("Y = %.4f + %.4f*x1 + %.4f*x2\n", model$coefficients[1], model$coefficients[2], model$coefficients[3]))

#Gr√°ficos de contorno

#se o melhor modelo fosse com intera√ß√£o, apenas trocar√≠amos model por ciro nos modelos
# os gr√°ficos de cotorno com intera√ß√£o apresentam curvas e/ou ondula√ß√µes, inclina√ß√µes

contour(model, ~x1+x2,
        image = TRUE,
        xlabs = c("X1", "X2")
        )
points(dados$X1, dados$X2)
#As cores indicam diferentes valores da vari√°vel resposta ùëå
#Y Verde ‚Üí valores menores
#Y Vermelho/laranja ‚Üí valores maiores de ùëå
#As linhas com valores num√©ricos representam regi√µes de mesmo valor da resposta 
#Quanto mais pr√≥ximas essas linhas est√£o, maior a varia√ß√£o de Y em uma determinada regi√£o
#Linhas inclinadas sugerem que ambas as vari√°veis afetam a resposta

persp(model, ~x1+x2, contours = "colors",
      zlab = "Y",
      xlabs = c("X1", "X2"))


######### QUEST√ÉO 3
library(FrF2)

planej = FrF2(nfactors = 4,
              
              nruns = 2^4,
              
              factor.names =c("Temperatura" ,"Catalisador", "Rea√ß√£o", "Ph") ,
              
              replications = 1,
              
              randomize = FALSE)

rendimento <- c(54, 85, 49, 62, 64, 94, 56, 70, 52, 87, 49,
                64, 64, 94, 58, 73)
planej <- add.response(planej, rendimento)

modelo <- lm(rendimento ~ Temperatura*Catalisador*`Rea√ß√£o`*Ph, data =
              planej)

anov <- aov(modelo)
summary(anov)
#uma grande soma dos quadrados indica que explica uma grande parte da variabilidade na resposta - sugere que √© um fator importante no processo

#retirando intera√ß√µes n√£o significativas - mantendo apenas a intera√ß√£o de tempertaura e catalisador
modelo2 <- lm(rendimento ~ Temperatura*Catalisador + `Rea√ß√£o` +Ph, data =
               planej)
anov2 <- aov(modelo2)
summary(anov2)
#grande soma dos quadrados, baixo valor-p e a alta estat√≠stica F um fator importante
#quadrado m√©dio dos res√≠duos (1,6) √© relativamente baixo, o que indica que o modelo explica a maior parte da variabilidade nos dados
#ph tem valor p maior que 0.05 e explica pouca variabilidade do modelo, vamos retir√°-lo

#retirando ph
modelo3 <- lm(rendimento ~ Temperatura*Catalisador + `Rea√ß√£o`, data =
                planej)
anov3 <- aov(modelo3)
summary(anov3)

anova(modelo, modelo2, modelo3) #indica que o modelo 2 tem menos RSS, modelo 1 √© saturado
# o modelo 2 √©  final

# Testando normalidade dos res√≠duos
shapiro.test(modelo2$residuals)

# Testando homovedasticidade
# Extrair os res√≠duos do modelo ANOVA
residuos <- residuals(modelo2)

# Realizar o teste de Bartlett
bartlett.test(residuos ~ Temperatura, data = planej)
bartlett.test(residuos ~ Catalisador, data = planej)
bartlett.test(residuos ~ `Rea√ß√£o`, data = planej)
bartlett.test(residuos ~ Ph, data = planej)

# como n√£o temos repeti√ß√µes, cada observa√ß√£o √© um n√≠vel diferente
tratamentos<-rep(c(paste("T",1:16)))
bartlett.test(residuos ~ tratamentos, data = planej)

# Testando independ√™ncia dos res√≠duos
lmtest::dwtest(anov2)

#Teste de compara√ß√µes
library(ExpDes.pt)
# Se voc√™ quiser fazer compara√ß√µes m√∫ltiplas com Tukey
library(multcomp)
# Realizando o teste de Tukey
teste_tukey <- glht(modelo2, linfct = mcp(Temperatura = "Tukey", Catalisador = "Tukey", `Rea√ß√£o` = "Tukey", Ph = "Tukey"))

# Resumo do teste
summary(teste_tukey)
