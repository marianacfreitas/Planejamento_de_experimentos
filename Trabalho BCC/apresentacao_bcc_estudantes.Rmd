---
title: "Blocos Completamente Aleatorizados"
author: "Mariana Freitas e Aline Pires"
date: ' '
output:
  beamer_presentation: default
  ioslides_presentation: default
---

# O que são Blocos Completamente Aleatorizados

Blocos completamente aleatorizados são uma forma de organizar experimentos para comparar os tratamentos, controlando fatores que poderiam atrapalhar os resultados.
Primeiro, as unidades experimentais são agrupadas em blocos de forma homogênea e depois, dentro de cada bloco, os tratamentos são atribuídos aleatoriamente às unidades, garantindo que a comparação entre tratamentos seja justa dentro de cada bloco. Essa comparação é feita por meio de uma análise de variância (ANOVA).

Como é analisado por ANOVA, os dados devem seguir alguns pressupostos para garantir que os resultados sejam válidos. Esses pressupostos são: Normalidade dos resíduos e Homocedasticidade
Isso significa que os erros devem ser distribuídos de forma simétrica ao redor da média e a dispersão dos erros não pode mudar dependendo do bloco.

---

# Aplicação

O dataset "Student Lifestyle" reúne informações sobre os hábitos diários e o desempenho acadêmico de 2.000 estudantes, coletadas por meio de uma pesquisa realizada com um Google Form. Abrangendo o período acadêmico de agosto de 2023 a maio de 2024, os dados refletem majoritariamente os estilos de vida de estudantes da Índia.

---

# Aplicação
O conjunto de dados contém as seguintes colunas:

- student_id: Identificador único de cada estudante.
- study_hours_per_day: Horas diárias dedicadas aos estudos.
- extracurricular_hours_per_day: Horas diárias envolvidas em atividades extracurriculares.
- sleep_hours_per_day: Horas diárias de sono.
- social_hours_per_day: Horas diárias dedicadas à socialização.
- physical_activity_hours_per_day: Horas diárias gastas em atividades físicas.
- gpa: Nota média acumulada (GPA) dos estudantes.
- stress_level: Nível de estresse relatado pelos participantes.

---

# Aplicação

A variável "stress_level" será utilizada para formar os blocos, agrupando os estudantes conforme seus níveis de estresse relatados. Já a "social_hours_per_day" será usada como o tratamento, analisando o impacto de diferentes níveis de socialização.

Para facilitar a análise, as horas de socialização foram classificadas em três categorias:

- Pouco: $\leq$ 2 horas por dia.
- Moderado: $\leq$ 4 horas por dia.
- Muito: $>$ 4 horas por dia.

```{r, message= FALSE, warning=FALSE, size= "footnotesize", echo=FALSE}
#https://www.kaggle.com/datasets/steve1215rogg/student-lifestyle-dataset
library(readr)
library(dplyr)
library(janitor)
library(ggplot2)

dados <- read_csv("student_lifestyle_dataset.csv") |> clean_names()

#Criando variáveis de bloco e tratamento
dados <- dados |>
  mutate(Bloco = as.factor(stress_level),
         Tratamento = cut(social_hours_per_day, breaks = 3, labels = c("Pouco", "Moderado", "Muito")))
```

---

# Homocedasticidade

A homocedasticidade é um pressuposto que afirma que a variância dos resíduos de um modelo é constante para todos os níveis dos fatores. Ou seja, a dispersão dos dados ao redor da média deve ser uniforme em todos os grupos ou categorias analisados.

Para verificar se os dados atendem ao pressuposto de homocedasticidade, utilizamos duas abordagens complementares: o gráfico de box-plot e o teste de Bartlett.

Com o box-plot, observamos as alturas das caixas e a extensão dos bigodes para avaliar se as variâncias aparentam ser semelhantes entre os grupos. Já o teste de Bartlett verifica se as variâncias são significativamente diferentes com um teste de hipótese, se o p-valor for pequeno, menor que 0.05, rejeitamos a hipótese de que as variâncias são iguais.

---

# Homocedasticidade

```{r, message = FALSE, warning=FALSE, size= "footnotesize", echo=FALSE}
ggplot(dados, aes(x = Tratamento, y = gpa, fill = Tratamento)) +
  geom_boxplot() +
  theme_light() +
  scale_fill_manual(values = c("#d694ad", "purple", "#7a0629"))  # Substitua pelas cores desejadas
```

---

# Homocedasticidade

Como as alturas das caixas nao apresentam grandes diferenças de tamanho, pode-se ter um indicativo do cumprimento do pressuposto de homocedasticidade.

---

# Homocedasticidade

```{r, message=FALSE, warning=FALSE, size= "footnotesize", echo=FALSE}

tratamento1 <- filter(dados, Tratamento == "Pouco")$gpa
tratamento2 <- filter(dados, Tratamento == "Moderado")$gpa
tratamento3 <- filter(dados, Tratamento == "Muito")$gpa

dados_homoc <- list(tratamento1, tratamento2, tratamento3)

resultado <- bartlett.test(dados_homoc)
print(resultado)

```

Como o valor-p não é pequeno o suficiente para rejeitar a hipótese nula, não há evidências estatísticas para afirmar que as variâncias dos grupos são diferentes.

---

# ANOVA

É uma técnica estatística usada para comparar as médias de mais de dois grupos e verificar se existem diferenças significativas entre elas. Testamos se as médias dos grupos são iguais.

```{r, message=FALSE, warning=FALSE, size= "footnotesize", echo=FALSE}

anova_model <- aov(gpa~ Tratamento + Bloco, data = dados)
anova_table <- anova(anova_model)
print(anova_table)

```

Os resultados indicam que tanto as horas de socialização quanto o nível de estresse afetam significativamente o desempenho acadêmico.
O nível de estresse (Bloco) parece explicar uma porção muito maior da variabilidade (Sum Sq = 53.405) em comparação com o efeito das horas de socialização (Sum Sq = 1.354).

---

# ANOVA

O gráfico abaixo apresenta a distribuição F, usada para testar a diferença entre as médias dos grupos na ANOVA:

- Área azul clara: Região crítica onde rejeitamos a hipótese nula.
- Linha azul (F Crítico): Limite superior da área crítica, determinado pelo nível de significância ($\alpha = 0,1$).
- Linha vermelha (F Calculado): Valor obtido da ANOVA. Se estiver à direita do F crítico, indica que há diferença significativa entre os grupos e a hipótese nula é rejeitada.

---

# ANOVA

```{r, message=FALSE, warning=FALSE, echo=FALSE, size= "footnotesize"}
# Graus de liberdade
k <- length(unique(dados$Tratamento)) # Número de grupos
N <- nrow(dados) # Total de observações
df1 <- k - 1 # Graus de liberdade entre grupos
df2 <- N - k # Graus de liberdade dentro dos grupos

# Nível de significância
alpha <- 0.1

# Valor crítico da tabela F
f_critico <- qf(1 - alpha, df1, df2)

#Valor de F calculado
f_calculado <- anova_table["Tratamento", "F value"]

# Criar uma sequência de valores para a curva F
x <- seq(-2, 11, by = 0.01)
y <- df(x, df1, df2)

# Criar o gráfico
plot(x, y, type = "l", lwd = 2, col = "black",
     main = "Distribuição F com Ponto Crítico",
     xlab = "Valor F", ylab = "Densidade",
     xlim = c(0, 11), ylim = c(0, max(y) * 1.1))

# Criando um polígono para a área a ser destacada
idx <- which(x >= f_critico)
polygon(c(x[idx], rev(x[idx])), c(y[idx], rep(0, length(idx))), col = 'lightblue')

# Adicionar o ponto crítico
abline(v = f_critico, col = "blue", lwd = 2, lty = 2)
legend("topleft", legend = paste("Ponto Crítico F =",round(f_critico, 2)),
       col = "blue", lty = 2, lwd = 2)

# Adicionar o F calculado
abline(v = f_calculado, col = "red", lwd = 2, lty = 2)
legend("topright", legend = paste("F calculado =", round(f_calculado, 2)),
       col = "red", lty = 2, lwd = 2)
```

Como o valor obtido da ANOVA está à direita do F crítico, rejeitamos a hipótese nula. Portanto, há diferença entre os grupos.

---

# Normalidade dos resíduos

Significa que os resíduos (as diferenças entre os valores observados e os previstos pelo modelo) devem seguir uma distribuição normal.

```{r, message=FALSE, warning=FALSE, echo=FALSE, size= "footnotesize"}
#Normalidade
residuos <- anova_model$residuals

# QQ-Plot com cores personalizadas
ggplot(data.frame(residuos), aes(sample = residuos)) +
  stat_qq(color = "#b53a69") +  # Cor azul suave para os pontos
  stat_qq_line(color = "black", size = 0.8) +  # Cor vermelha suave para a linha
  ggtitle("QQplot dos Resíduos") +
  xlab("Quantis Teóricos (Normal)") +
  ylab("Quantis da Amostra") + 
  theme_gray()

```

---

# Normalidade dos resíduos

Aparentemente os resíduos seguem uma distribuição normal, porém os resíduos de valores mais baixos se dispersam um pouco da linha teórica mas logo se ajustam.

---

# Normalidade dos resíduos

O teste de Shapiro-Wilk  é utilizado para verificar a normalidade dos dados. Ele compara a distribuição dos dados com uma distribuição normal e testa a hipótese nula de que os dados seguem uma distribuição normal. Se o valor-p for menor que o nível de significância, rejeitamos a hipótese nula, indicando que resíduos não são normalmente distribuídos.


```{r, message=FALSE, warning=FALSE, size= "footnotesize", echo=FALSE}
shapiro_wilk <- shapiro.test(residuos)
print(shapiro_wilk)
```

Como o p-valor é muito baixo, rejeitamos a hipótese que os dados são normalmente distribuídos.

---

# Teste de comparações múltiplas

O teste de comparações múltiplas é utilizado após a ANOVA para identificar quais grupos específicos apresentam diferenças significativas entre si, quando a ANOVA indica uma diferença geral.
Como a ANOVA apenas informa se existe diferença, mas não qual grupo é diferente dos outros, os testes de comparações múltiplas ajudam a realizar comparações entre os pares de grupos.

Como rejeitamos a hipótese nula na ANOVA, usaremos esse teste.

---

# Teste de Scheffé

O teste de Scheffé é um dos testes de comparações múltiplas. Ele é usado para fazer comparações entre as médias de diferentes grupos após uma ANOVA.

---

# Teste de Scheffé

```{r, message=FALSE, warning=FALSE, size= "footnotesize", echo=FALSE}
library(DescTools)
scheffe <- ScheffeTest(anova_model)
print(scheffe)
```

---

# Teste de Scheffé

Conclusões: o tratamento (horas de socialização): Há diferenças significativas entre os grupos Muito e Pouco de socialização, e entre Muito e Moderado. 
Já o Bloco (nível de estresse): As comparações entre os diferentes níveis de estresse (Low, Moderate e High) revelaram diferenças significativas, com os estudantes de baixo estresse apresentando desempenho distinto dos de estresse alto.





